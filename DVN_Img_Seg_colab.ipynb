{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DVN_Img_Seg.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/philqc/Structured_Prediction/blob/master/DVN_Img_Seg_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WwSE_tJAGvEr",
        "colab_type": "code",
        "outputId": "745ea820-291a-4380-e9e7-5327923875f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms, utils\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import random\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "import math\n",
        "import copy\n",
        "import pdb\n",
        "from skimage import io"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 753.6MB 59.0MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 12.1MB/s \n",
            "\u001b[31mimgaug 0.2.8 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MxsJs2SaUxbo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For some reason, we are getting AttributeError: module 'PIL.Image' has no attribute 'register_extensions if we don't install pillow version 4.1.1"
      ]
    },
    {
      "metadata": {
        "id": "eR3Ddub5UvWH",
        "colab_type": "code",
        "outputId": "89fbcdfd-8eec-4cc6-f692-adb70db53139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pillow==4.1.1\n",
        "%reload_ext autoreload\n",
        "%autoreload"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pillow==4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e5/88b3d60924a3f8476fa74ec086f5fbaba56dd6cee0d82845f883b6b6dd18/Pillow-4.1.1-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.7MB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow==4.1.1) (0.46)\n",
            "\u001b[31mimgaug 0.2.8 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 5.4.1\n",
            "    Uninstalling Pillow-5.4.1:\n",
            "      Successfully uninstalled Pillow-5.4.1\n",
            "Successfully installed pillow-4.1.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "SmxcaxcyJK6f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load the dataset"
      ]
    },
    {
      "metadata": {
        "id": "sOlkh_0KJIXm",
        "colab_type": "code",
        "outputId": "1624e106-e86f-4544-d0db-07e43cb7928c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# directory path to store results/plots/models\n",
        "dir_path = 'drive/My Drive/projet_asp/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kVVBr6lYHZJv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Auxiliary functions"
      ]
    },
    {
      "metadata": {
        "id": "sV6i9KA3HVjG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Adam:\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "\n",
        "        self.v = torch.zeros_like(params)\n",
        "        self.m = torch.zeros_like(params)\n",
        "        self.betas = betas\n",
        "        self.lr = lr\n",
        "        self.eps = eps\n",
        "        self.t = 0\n",
        "\n",
        "    def update(self, gradients):\n",
        "        # update time step\n",
        "        self.t += 1\n",
        "\n",
        "        self.m = self.betas[0] * self.m + (1 - self.betas[0]) * gradients\n",
        "        self.v = self.betas[1] * self.v + (1 - self.betas[1]) * (gradients ** 2)\n",
        "\n",
        "        # Bias corrected first and second moment estimates\n",
        "        mean = self.m / (1 - self.betas[0] ** self.t)\n",
        "        variance = self.v / (1 - self.betas[1] ** self.t)\n",
        "\n",
        "        update = self.lr * mean / (torch.sqrt(variance) + self.eps)\n",
        "        return update\n",
        "\n",
        "\n",
        "class SGD:\n",
        "\n",
        "    def __init__(self, params, lr=0.5, momentum=0., weight_decay=0.0):\n",
        "        \"\"\"\n",
        "        SGD with momentum for the inference part of\n",
        "        training/testing. This speeds up training by using\n",
        "        autograd.grad of the loss with respect to only the inputs\n",
        "        but optimizer of pytorch is not compatible, so we make\n",
        "        our own optimizer function\n",
        "        \"\"\"\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if momentum < 0.0:\n",
        "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
        "        if weight_decay < 0.0:\n",
        "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
        "\n",
        "        self.lr = lr\n",
        "        self.momentum = momentum\n",
        "        self.v = torch.zeros_like(params)\n",
        "\n",
        "    def update(self, gradients):\n",
        "        self.v = self.momentum * self.v + self.lr * gradients\n",
        "        return self.v\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "\n",
        "    def __init__(self, inputs, labels):\n",
        "        self.inputs = inputs\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.inputs[index], self.labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "\n",
        "def print_a_sentence(x, y, txt_inputs, txt_labels):\n",
        "    \"\"\" To visualize the data \"\"\"\n",
        "    print('-----------------')\n",
        "    for i, x in enumerate(x):\n",
        "        if x == 1:\n",
        "            print(txt_inputs[i])\n",
        "    \n",
        "    print('-----------------')\n",
        "    print('TAGS:')\n",
        "    for i, y in enumerate(y):\n",
        "        if y == 1:\n",
        "            print(txt_labels[i])\n",
        "    \n",
        "\n",
        "def compute_f1_score(labels, outputs):\n",
        "    \"\"\" \n",
        "    Compute the example averaged (macro average) F1 measure\n",
        "    \"\"\"\n",
        "    assert labels.shape == outputs.shape\n",
        "\n",
        "    f1 = []\n",
        "    for i in range(len(outputs)):\n",
        "        f1.append(f1_score(labels[i], outputs[i]))\n",
        "\n",
        "    return np.mean(f1)\n",
        "\n",
        "\n",
        "def plot_results(results):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    ----------\n",
        "    results: dictionary with the train/valid loss\n",
        "    and the f1 scores\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    ax1.set_title('Validation Loss')\n",
        "    ax1.set_ylabel('loss')\n",
        "    ax1.set_xlabel('epochs')\n",
        "    ax2.set_title('Validation F1 Score')\n",
        "    ax2.set_ylabel('F1 Score')\n",
        "    ax2.set_xlabel('epochs')\n",
        "\n",
        "    ax1.plot(results['loss_train'], label='loss_train')\n",
        "    ax1.plot(results['loss_valid'], label='loss_valid')\n",
        "    ax2.plot(results['f1_valid'])\n",
        "\n",
        "    ax1.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_aggregate_results(results_path, add_title=''):\n",
        "\n",
        "    array_results = []\n",
        "    for filename in os.listdir(results_path):\n",
        "        if filename.endswith('.pkl'):\n",
        "            with open(os.path.join(results_path, filename), 'rb') as fin:\n",
        "                array_results.append(pickle.load(fin))\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    ax1.set_title('Validation Loss ' + add_title)\n",
        "    ax1.set_ylabel('loss')\n",
        "    ax1.set_xlabel('epochs')\n",
        "    ax2.set_title('Validation F1 Score ' + add_title)\n",
        "    ax2.set_ylabel('F1 Score')\n",
        "    ax2.set_xlabel('epochs')\n",
        "\n",
        "    # max number of epochs\n",
        "    max_ep = 60\n",
        "\n",
        "    for res in array_results:\n",
        "\n",
        "        if res['name'] == 'SPEN_bibtex':\n",
        "            res['name'] = 'SPEN'\n",
        "\n",
        "        label = res['name']\n",
        "\n",
        "        # ax1.plot(res['loss_train'][:max_ep], label=label)\n",
        "        if res['name'] != 'SPEN':\n",
        "            ax1.plot(res['loss_valid'][:max_ep], label=label)\n",
        "        ax2.plot(res['f1_valid'][:max_ep], label=label)\n",
        "\n",
        "    ax1.legend()\n",
        "    ax2.legend()\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CdrrDwXwJeyY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Deep Value Network"
      ]
    },
    {
      "metadata": {
        "id": "oYL18v4OHO1O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build the dataset, generate the \"training tuple\"\n",
        "class WeizmannHorseDataset(Dataset):\n",
        "    \"\"\" Weizmann Horse Dataset \"\"\"\n",
        "    \n",
        "    def __init__(self, img_dir, mask_dir, test_set, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img_dir(string): Path to the image file (training image)\n",
        "            mask_dir(string): Path to the mask file (segmentation result)\n",
        "            test_set(bool): if we want test set or train set\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.img_dir = img_dir\n",
        "        self.mask_dir = mask_dir\n",
        "\n",
        "        all_img_names = os.listdir(img_dir)\n",
        "        all_mask_names = os.listdir(mask_dir)\n",
        "\n",
        "        self.img_names = []\n",
        "        self.mask_names = []\n",
        "        for i, name in enumerate(all_img_names):\n",
        "            img_number = ''.join([n for n in name if n.isdigit()])\n",
        "            if int(img_number) >= 200:\n",
        "                if test_set:\n",
        "                    self.img_names.append(name)\n",
        "                    self.mask_names.append(all_mask_names[i])\n",
        "            else:\n",
        "                self.img_names.append(name)\n",
        "                self.mask_names.append(all_mask_names[i])\n",
        "\n",
        "        assert len(self.mask_names) == len(self.img_names)\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, self.img_names[idx])\n",
        "        mask_name = os.path.join(self.mask_dir, self.mask_names[idx])\n",
        "        \n",
        "        image = io.imread(img_name)\n",
        "        mask = io.imread(mask_name)\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "            #create a channel for mask so as to transform\n",
        "            mask = self.transform(np.expand_dims(mask, axis=2))\n",
        "            \n",
        "        return image, mask\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "\n",
        "    # define each layer of neural network\n",
        "    def __init__(self, non_linearity=nn.ELU()):\n",
        "        super().__init__()\n",
        "        # Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
        "        self.conv1 = nn.Conv2d(4, 64, 5, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 5, 2)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(128, 128, 5, 2)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        # Linear(in_features, out_features, bias=True)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 384)\n",
        "\n",
        "        self.fc2 = nn.Linear(384, 192)\n",
        "        self.fc3 = nn.Linear(192, 1)\n",
        "        self.non_linearity = non_linearity\n",
        "\n",
        "    # define how input will be processed through those layers\n",
        "    def forward(self, x, y):\n",
        "        # We first concatenate the img and the mask\n",
        "        z = torch.cat((x, y), 1)\n",
        "        z = self.non_linearity(self.bn1(self.conv1(z)))\n",
        "        z = self.non_linearity(self.bn2(self.conv2(z)))\n",
        "        z = self.non_linearity(self.bn3(self.conv3(z)))\n",
        "        # don't forget to flatten before connect to FC layers\n",
        "        z = z.view(-1, 128 * 4 * 4)\n",
        "        z = self.non_linearity(self.fc1(z))\n",
        "        # apply dropout on the first FC layer as paper mentioned\n",
        "        z = F.dropout(z, p=0.75)\n",
        "        z = self.non_linearity(self.fc2(z))\n",
        "        z = self.non_linearity(self.fc3(z))\n",
        "        return z\n",
        "\n",
        "\n",
        "class DeepValueNetwork:\n",
        "\n",
        "    def __init__(self, dataset, use_cuda, add_adversarial=True,\n",
        "                 add_ground_truth=False, stratified_sampling=False, batch_size=16, batch_size_eval=16,\n",
        "                 learning_rate=1e-3, inf_lr=0.5, feature_dim=(32, 32), label_dim=(32, 32),\n",
        "                 non_linearity=nn.ELU()):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        use_cuda: boolean\n",
        "            true if we are using gpu, false if using cpu\n",
        "        learning_rate : float\n",
        "            learning rate for updating the value network parameters\n",
        "        inf_lr : float\n",
        "            learning rate for the inference procedure\n",
        "        add_adversarial: bool\n",
        "            Generate adversarial tuples while training.\n",
        "            (Usually outperforms stratified sampling and adding ground truth)\n",
        "        stratified_sampling: bool (Not yet implemented)\n",
        "            Sample y proportional to its exponential oracle value.\n",
        "            Sample from the exponentiated value distribution using stratified sampling.\n",
        "        add_ground_truth: bool\n",
        "            Simply add the ground truth outputs y* with some probably p while training.\n",
        "        \"\"\"\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "        self.add_adversarial = add_adversarial\n",
        "        self.add_ground_truth = add_ground_truth\n",
        "        self.stratified_sampling = stratified_sampling\n",
        "        if self.stratified_sampling:\n",
        "            raise ValueError('Stratified sampling is not yet implemented!')\n",
        "        if self.add_ground_truth and self.add_adversarial:\n",
        "            raise ValueError('Adversarial examples and Adding Ground Truth are both set to true !')\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.label_dim = label_dim\n",
        "        self.inf_lr = inf_lr\n",
        "\n",
        "        # Deep Value Network is just a ConvNet\n",
        "        self.model = ConvNet(non_linearity).to(self.device)\n",
        "\n",
        "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.batch_size_eval = batch_size_eval\n",
        "\n",
        "        self.n_train = int(len(dataset) * 0.80)\n",
        "        self.n_valid = len(dataset) - self.n_train\n",
        "\n",
        "        print('Using a {} train {} valid data-split'.format(self.n_train, self.n_valid))\n",
        "        indices = list(range(len(dataset)))\n",
        "        random.shuffle(indices)\n",
        "\n",
        "        self.train_loader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            sampler=SubsetRandomSampler(indices[:self.n_train]),\n",
        "            pin_memory=use_cuda\n",
        "        )\n",
        "\n",
        "        self.valid_loader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.batch_size_eval,\n",
        "            sampler=SubsetRandomSampler(indices[self.n_train:]),\n",
        "            pin_memory=use_cuda\n",
        "        )\n",
        "\n",
        "        # turn on/off\n",
        "        self.training = False\n",
        "\n",
        "\n",
        "    def get_oracle_value(self, pred_labels, gt_labels):\n",
        "        \"\"\"\n",
        "        Compute the ground truth value, i.e. v*(y, y*)\n",
        "        of some predicted labels, where v*(y, y*)\n",
        "        is the relaxed version of the F1 Score.\n",
        "        \"\"\"\n",
        "        if pred_labels.shape != gt_labels.shape:\n",
        "            raise ValueError('Invalid labels shape: gt = ', gt_labels.shape, 'pred = ', pred_labels.shape)\n",
        "\n",
        "        if not self.training:\n",
        "            # No relaxation, 0-1 only\n",
        "            pred_labels = torch.where(pred_labels >= 0.5, \n",
        "                                      torch.ones(1).to(self.device), \n",
        "                                      torch.zeros(1).to(self.device))\n",
        "            pred_labels = pred_labels.float()\n",
        "\n",
        "        pred_labels = torch.flatten(pred_labels).reshape(pred_labels.size()[0], -1)\n",
        "        gt_labels = torch.flatten(gt_labels).reshape(gt_labels.size()[0], -1)\n",
        "\n",
        "        intersect = torch.sum(torch.min(pred_labels, gt_labels), dim=1)\n",
        "        union = torch.sum(torch.max(pred_labels, gt_labels), dim=1)\n",
        "\n",
        "        # for numerical stability\n",
        "        epsilon = torch.full(union.size(), 10 ** -8).to(self.device)\n",
        "\n",
        "        relaxed_iou = intersect / torch.max(epsilon, union)\n",
        "        # we want a (Batch_size x 1) tensor\n",
        "        relaxed_iou = relaxed_iou.view(-1, 1)\n",
        "        #pdb.set_trace()\n",
        "        return relaxed_iou\n",
        "\n",
        "    def get_ini_labels(self, x, gt_labels=None):\n",
        "        \"\"\"\n",
        "        Get the tensor of predicted labels\n",
        "        that we will do inference on\n",
        "        \"\"\"\n",
        "        y = torch.zeros(x.size()[0], 1, self.label_dim[0], self.label_dim[1],\n",
        "                        dtype=torch.float32, device=self.device)\n",
        "\n",
        "        if gt_labels is not None:\n",
        "            # 50%: Start from GT; rest: start from zeros\n",
        "            gt_indices = torch.rand(gt_labels.shape[0]).float().to(self.device) > 0.5\n",
        "            y[gt_indices] = gt_labels[gt_indices]\n",
        "\n",
        "        # Set requires_grad=True after in_place operation (changing the indices)\n",
        "        y.requires_grad = True\n",
        "        return y\n",
        "\n",
        "    def generate_output(self, x, gt_labels):\n",
        "        \"\"\"\n",
        "        Generate an output y to compute\n",
        "        the loss v(y, y*) --> we can use different\n",
        "        techniques to generate the output\n",
        "        1) Gradient based inference\n",
        "        2) Simply add the ground truth outputs\n",
        "        2) Generating adversarial tuples\n",
        "        3) TODO: Stratified Sampling: Random samples from Y, biased towards y*\n",
        "        \"\"\"\n",
        "\n",
        "        if self.add_adversarial and self.training and np.random.rand() >= 0.5:\n",
        "            # In training: Generate adversarial examples 50% of the time\n",
        "            init_labels = self.get_ini_labels(x, gt_labels=gt_labels)\n",
        "            pred_labels = self.inference(x, init_labels, gt_labels=gt_labels, num_iterations=1)\n",
        "        elif self.add_ground_truth and self.training and np.random.rand() >= 0.5:\n",
        "            # In training: If add_ground_truth=True, add ground truth outputs\n",
        "            # to provide some positive examples to the network\n",
        "            pred_labels = gt_labels\n",
        "        else:\n",
        "            init_labels = self.get_ini_labels(x)\n",
        "            pred_labels = self.inference(x, init_labels)\n",
        "\n",
        "        return pred_labels\n",
        "\n",
        "    def inference(self, x, y, gt_labels=None, num_iterations=20):\n",
        "\n",
        "        if self.training:\n",
        "            self.model.eval()\n",
        "\n",
        "        #optim_inf = SGD(y, lr=2, momentum=0.9)\n",
        "        optim_inf = Adam(y, lr=0.5)\n",
        "\n",
        "        with torch.enable_grad():\n",
        "\n",
        "            for i in range(num_iterations):\n",
        "\n",
        "                if gt_labels is not None:  # Adversarial\n",
        "                    oracle = self.get_oracle_value(y, gt_labels)\n",
        "                    output = self.model(x, y)\n",
        "                    # this is the BCE loss with logits\n",
        "                    value = self.loss_fn(output, oracle)\n",
        "                else:\n",
        "                    output = self.model(x, y)\n",
        "                    value = torch.sigmoid(output)\n",
        "\n",
        "                grad = torch.autograd.grad(value, y, grad_outputs=torch.ones_like(value),\n",
        "                                           only_inputs=True)\n",
        "\n",
        "                y_grad = grad[0].detach()\n",
        "                #pdb.set_trace()\n",
        "                y = y + optim_inf.update(y_grad)\n",
        "                # Project back to the valid range\n",
        "                y = torch.clamp(y, 0, 1)\n",
        "               \n",
        "\n",
        "        if self.training:\n",
        "            self.model.train()\n",
        "\n",
        "        return y\n",
        "\n",
        "    def train(self, ep):\n",
        "\n",
        "        self.model.train()\n",
        "        self.training = True\n",
        "\n",
        "        time_start = time.time()\n",
        "        t_loss, t_size = 0, 0\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(self.train_loader):\n",
        "\n",
        "            inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
        "            inputs, targets = inputs.float(), targets.float()\n",
        "\n",
        "            t_size += len(inputs)\n",
        "\n",
        "            self.model.zero_grad()\n",
        "\n",
        "            pred_labels = self.generate_output(inputs, targets)\n",
        "            oracle = self.get_oracle_value(pred_labels, targets)\n",
        "            output = self.model(inputs, pred_labels)\n",
        "\n",
        "            loss = self.loss_fn(output, oracle)\n",
        "            t_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            if batch_idx % 2 == 0:\n",
        "                print('\\rTraining Epoch {} [{} / {} ({:.0f}%)]: Time per epoch: {:.2f}s; Avg_Loss = {:.5f}; IOU = {:.2f}%'\n",
        "                      ''.format(ep, t_size, self.n_train, 100 * t_size / self.n_train,\n",
        "                                (self.n_train / t_size) * (time.time() - time_start), t_loss / t_size, 100*oracle.mean()),\n",
        "                      end='')\n",
        "\n",
        "        t_loss /= t_size\n",
        "        self.training = False\n",
        "        print('')\n",
        "        return t_loss\n",
        "\n",
        "    def valid(self, loader, test_set=False):\n",
        "\n",
        "        self.model.eval()\n",
        "        self.training = False\n",
        "\n",
        "        loss, t_size = 0, 0\n",
        "        mean_iou = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for (inputs, targets) in loader:\n",
        "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
        "                inputs, targets = inputs.float(), targets.float()\n",
        "                t_size += len(inputs)\n",
        "\n",
        "                pred_labels = self.generate_output(inputs, targets)\n",
        "                oracle = self.get_oracle_value(pred_labels, targets)\n",
        "                output = self.model(inputs, pred_labels)\n",
        "                \n",
        "                loss += self.loss_fn(oracle, output)\n",
        "\n",
        "                mean_iou.append(oracle.mean())\n",
        "        \n",
        "        mean_iou = torch.stack(mean_iou)\n",
        "        mean_iou = torch.mean(mean_iou)\n",
        "        loss /= t_size\n",
        "\n",
        "        if test_set:\n",
        "            print('Test set: Avg_Loss = {:.2f};  IOU = {:.2f}%'\n",
        "                  ''.format(loss.item(), 100 * mean_iou))\n",
        "        else:\n",
        "            print('Validation set: Avg_Loss = {:.2f}; IOU = {:.2f}%'\n",
        "                  ''.format(loss.item(), 100 * mean_iou))\n",
        "\n",
        "        return loss.item(), mean_iou\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z5pWSv5OWqMu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load bibtex and choose to use cpu or gpu"
      ]
    },
    {
      "metadata": {
        "id": "RBWt5LiCWnhc",
        "colab_type": "code",
        "outputId": "60ebaa70-a1e0-44cb-b518-4e653c44afbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Use GPU if it is available\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('using cuda =', use_cuda)\n",
        "    \n",
        "image_dir = dir_path + './images'\n",
        "mask_dir = dir_path + './masks'\n",
        "\n",
        "WhorseDataset = WeizmannHorseDataset(image_dir, mask_dir, test_set=False,\n",
        "                                     transform=transforms.Compose([\n",
        "                                               transforms.ToPILImage(),\n",
        "                                               transforms.Resize(size=(32, 32)),\n",
        "                                               transforms.ToTensor()\n",
        "                                     ]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cuda = True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H6Dehg2TWrVX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Run the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "izCw-KAgG6-Q",
        "colab_type": "code",
        "outputId": "c1fb906e-831b-4b60-c1e1-d02413c0a898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2969
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "DVN = DeepValueNetwork(WhorseDataset, use_cuda,\n",
        "                       add_adversarial=False, add_ground_truth=True,\n",
        "                       batch_size=32, batch_size_eval=32)\n",
        "\n",
        "# Decay the learning rate by a factor of gamma every step_size # of epochs\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(DVN.optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "results = {'name': 'DVN_Whorse', 'loss_train': [],\n",
        "           'loss_valid': [], 'IOU_valid': []}\n",
        "\n",
        "save_results_file = os.path.join(dir_path, results['name'] + '.pkl')\n",
        "\n",
        "for epoch in range(60):\n",
        "  loss_train = DVN.train(epoch)\n",
        "  loss_valid, IOU_valid = DVN.valid(DVN.valid_loader)\n",
        "  scheduler.step()\n",
        "  results['loss_train'].append(loss_train)\n",
        "  results['loss_valid'].append(loss_valid)\n",
        "  results['IOU_valid'].append(IOU_valid)\n",
        "\n",
        "with open(save_results_file, 'wb') as fout:\n",
        "  pickle.dump(results, fout)\n",
        "\n",
        "plot_results(results)\n",
        "torch.save(DVN.model.state_dict(), dir_path + '/' + results['name'] + '.pth')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using a 160 train 40 valid data-split\n",
            "Training Epoch 0 [160 / 160 (100%)]: Time per epoch: 1.23s; Avg_Loss = 0.02381; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 42.37%\n",
            "Training Epoch 1 [160 / 160 (100%)]: Time per epoch: 1.42s; Avg_Loss = 0.02092; IOU = 46.00%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 47.45%\n",
            "Training Epoch 2 [160 / 160 (100%)]: Time per epoch: 2.00s; Avg_Loss = 0.02602; IOU = 10.50%\n",
            "Validation set: Avg_Loss = 0.04; IOU = 11.50%\n",
            "Training Epoch 3 [160 / 160 (100%)]: Time per epoch: 2.00s; Avg_Loss = 0.02345; IOU = 31.93%\n",
            "Validation set: Avg_Loss = 0.05; IOU = 35.04%\n",
            "Training Epoch 4 [160 / 160 (100%)]: Time per epoch: 1.37s; Avg_Loss = 0.02331; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.04; IOU = 43.08%\n",
            "Training Epoch 5 [160 / 160 (100%)]: Time per epoch: 1.39s; Avg_Loss = 0.01946; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.01; IOU = 48.05%\n",
            "Training Epoch 6 [160 / 160 (100%)]: Time per epoch: 1.98s; Avg_Loss = 0.02578; IOU = 47.97%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 44.23%\n",
            "Training Epoch 7 [160 / 160 (100%)]: Time per epoch: 1.37s; Avg_Loss = 0.01880; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 41.02%\n",
            "Training Epoch 8 [160 / 160 (100%)]: Time per epoch: 1.37s; Avg_Loss = 0.01925; IOU = 40.12%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 43.36%\n",
            "Training Epoch 9 [160 / 160 (100%)]: Time per epoch: 1.40s; Avg_Loss = 0.01795; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 43.28%\n",
            "Training Epoch 10 [160 / 160 (100%)]: Time per epoch: 2.01s; Avg_Loss = 0.02613; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.04; IOU = 34.48%\n",
            "Training Epoch 11 [160 / 160 (100%)]: Time per epoch: 1.69s; Avg_Loss = 0.02207; IOU = 35.81%\n",
            "Validation set: Avg_Loss = 0.04; IOU = 41.41%\n",
            "Training Epoch 12 [160 / 160 (100%)]: Time per epoch: 1.98s; Avg_Loss = 0.02352; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.04; IOU = 23.23%\n",
            "Training Epoch 13 [160 / 160 (100%)]: Time per epoch: 1.98s; Avg_Loss = 0.02199; IOU = 26.81%\n",
            "Validation set: Avg_Loss = 0.05; IOU = 30.11%\n",
            "Training Epoch 14 [160 / 160 (100%)]: Time per epoch: 1.37s; Avg_Loss = 0.02322; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.04; IOU = 38.78%\n",
            "Training Epoch 15 [160 / 160 (100%)]: Time per epoch: 1.37s; Avg_Loss = 0.02085; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 43.27%\n",
            "Training Epoch 16 [160 / 160 (100%)]: Time per epoch: 2.30s; Avg_Loss = 0.02625; IOU = 48.17%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 45.92%\n",
            "Training Epoch 17 [160 / 160 (100%)]: Time per epoch: 1.69s; Avg_Loss = 0.02137; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.04; IOU = 41.19%\n",
            "Training Epoch 18 [160 / 160 (100%)]: Time per epoch: 1.99s; Avg_Loss = 0.02270; IOU = 34.82%\n",
            "Validation set: Avg_Loss = 0.04; IOU = 36.61%\n",
            "Training Epoch 19 [160 / 160 (100%)]: Time per epoch: 1.38s; Avg_Loss = 0.02040; IOU = 39.21%\n",
            "Validation set: Avg_Loss = 0.04; IOU = 39.21%\n",
            "Training Epoch 20 [160 / 160 (100%)]: Time per epoch: 1.07s; Avg_Loss = 0.01653; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 45.94%\n",
            "Training Epoch 21 [160 / 160 (100%)]: Time per epoch: 1.70s; Avg_Loss = 0.02192; IOU = 44.45%\n",
            "Validation set: Avg_Loss = 0.01; IOU = 47.33%\n",
            "Training Epoch 22 [160 / 160 (100%)]: Time per epoch: 1.37s; Avg_Loss = 0.01778; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 40.48%\n",
            "Training Epoch 23 [160 / 160 (100%)]: Time per epoch: 1.39s; Avg_Loss = 0.01822; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 43.30%\n",
            "Training Epoch 24 [160 / 160 (100%)]: Time per epoch: 1.37s; Avg_Loss = 0.01755; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 49.00%\n",
            "Training Epoch 25 [160 / 160 (100%)]: Time per epoch: 2.00s; Avg_Loss = 0.02386; IOU = 47.53%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 45.85%\n",
            "Training Epoch 26 [160 / 160 (100%)]: Time per epoch: 1.71s; Avg_Loss = 0.02020; IOU = 45.28%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 42.18%\n",
            "Training Epoch 27 [160 / 160 (100%)]: Time per epoch: 1.09s; Avg_Loss = 0.01574; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 47.24%\n",
            "Training Epoch 28 [160 / 160 (100%)]: Time per epoch: 1.77s; Avg_Loss = 0.02003; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 49.02%\n",
            "Training Epoch 29 [160 / 160 (100%)]: Time per epoch: 1.76s; Avg_Loss = 0.02025; IOU = 47.36%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 43.76%\n",
            "Training Epoch 30 [160 / 160 (100%)]: Time per epoch: 2.09s; Avg_Loss = 0.02293; IOU = 43.88%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 41.00%\n",
            "Training Epoch 31 [160 / 160 (100%)]: Time per epoch: 1.47s; Avg_Loss = 0.01801; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 41.85%\n",
            "Training Epoch 32 [160 / 160 (100%)]: Time per epoch: 2.03s; Avg_Loss = 0.02260; IOU = 45.33%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 41.63%\n",
            "Training Epoch 33 [160 / 160 (100%)]: Time per epoch: 1.37s; Avg_Loss = 0.01798; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 42.91%\n",
            "Training Epoch 34 [160 / 160 (100%)]: Time per epoch: 1.99s; Avg_Loss = 0.02256; IOU = 43.96%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 43.73%\n",
            "Training Epoch 35 [160 / 160 (100%)]: Time per epoch: 1.37s; Avg_Loss = 0.01801; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 43.69%\n",
            "Training Epoch 36 [160 / 160 (100%)]: Time per epoch: 1.40s; Avg_Loss = 0.01776; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 45.51%\n",
            "Training Epoch 37 [160 / 160 (100%)]: Time per epoch: 1.39s; Avg_Loss = 0.01759; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 44.72%\n",
            "Training Epoch 38 [160 / 160 (100%)]: Time per epoch: 1.69s; Avg_Loss = 0.01965; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 43.79%\n",
            "Training Epoch 39 [160 / 160 (100%)]: Time per epoch: 1.38s; Avg_Loss = 0.01705; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 47.23%\n",
            "Training Epoch 40 [160 / 160 (100%)]: Time per epoch: 1.77s; Avg_Loss = 0.01964; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 46.77%\n",
            "Training Epoch 41 [160 / 160 (100%)]: Time per epoch: 1.50s; Avg_Loss = 0.01672; IOU = 51.21%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 47.46%\n",
            "Training Epoch 42 [160 / 160 (100%)]: Time per epoch: 1.76s; Avg_Loss = 0.01917; IOU = 49.96%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 47.52%\n",
            "Training Epoch 43 [160 / 160 (100%)]: Time per epoch: 1.39s; Avg_Loss = 0.01653; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 48.60%\n",
            "Training Epoch 44 [160 / 160 (100%)]: Time per epoch: 1.09s; Avg_Loss = 0.01339; IOU = 49.69%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 48.13%\n",
            "Training Epoch 45 [160 / 160 (100%)]: Time per epoch: 1.38s; Avg_Loss = 0.01647; IOU = 51.78%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 47.24%\n",
            "Training Epoch 46 [160 / 160 (100%)]: Time per epoch: 1.69s; Avg_Loss = 0.01926; IOU = 49.69%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 48.32%\n",
            "Training Epoch 47 [160 / 160 (100%)]: Time per epoch: 1.69s; Avg_Loss = 0.01994; IOU = 46.58%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 47.09%\n",
            "Training Epoch 48 [160 / 160 (100%)]: Time per epoch: 1.11s; Avg_Loss = 0.01286; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 46.92%\n",
            "Training Epoch 49 [160 / 160 (100%)]: Time per epoch: 1.71s; Avg_Loss = 0.01924; IOU = 53.15%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 45.10%\n",
            "Training Epoch 50 [160 / 160 (100%)]: Time per epoch: 2.00s; Avg_Loss = 0.02347; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 48.32%\n",
            "Training Epoch 51 [160 / 160 (100%)]: Time per epoch: 1.69s; Avg_Loss = 0.01945; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 47.09%\n",
            "Training Epoch 52 [160 / 160 (100%)]: Time per epoch: 1.69s; Avg_Loss = 0.02008; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.02; IOU = 44.05%\n",
            "Training Epoch 53 [160 / 160 (100%)]: Time per epoch: 1.40s; Avg_Loss = 0.01670; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 43.07%\n",
            "Training Epoch 54 [160 / 160 (100%)]: Time per epoch: 1.07s; Avg_Loss = 0.01366; IOU = 100.00%\n",
            "Validation set: Avg_Loss = 0.03; IOU = 45.31%\n",
            "Training Epoch 55 [32 / 160 (20%)]: Time per epoch: 2.23s; Avg_Loss = 0.02710; IOU = 45.65%"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-af7ec896201b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDVN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mloss_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOU_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDVN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDVN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-b60bdd15da31>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, ep)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mt_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-4b268bd0f196>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_grey, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                                (plugin, kind))\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/io/_plugins/pil_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, dtype, img_num, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}